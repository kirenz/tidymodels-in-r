---
title: "Tidymodels I: Build a Model"
subtitle: "Learn how to build a regression model with tidymodels"
author: "Prof. Dr. Jan Kirenz"
output:
 html_document:
  code_download: true 
  fig_height: 8
  fig_width: 12
  highlight: tango
  number_sections: yes
  theme: paper
  toc: yes
  toc_depth: 3
  toc_float: 
    collapsed: false
    smooth_scroll: true 
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(tidymodels)
```

*This tutorial is based on Alisson Hill's excellent [tidymodels workshop](https://alison.rbind.io/tags/tidymodels/).* 

In this tutorial you will learn how to specify a model with the tidymodels package.

As data, we use 2,930 houses sold in Ames, IA from 2006 to 2010, collected by the Ames Assessor’s Oﬃce. From this dataset, we only select our dependent variable (`Sale_Price`) and one predictor variable (`Gr_Liv_Area`).

```{r}
library(tidyverse)

ames <- read_csv("https://raw.githubusercontent.com/kirenz/datasets/master/ames.csv")

ames <- 
  ames %>%
  select(Sale_Price, Gr_Liv_Area)

glimpse(ames)

```


# Simple process 

In this first example, we don't use data splitting.

## Model type

1. Pick an `model type`: choose from this [list](https://www.tidymodels.org/find/parsnip/)
2. Set the `engine`: choose from this [list](https://www.tidymodels.org/find/parsnip/)
3. Set the `mode`: regression or classification

```{r}
library(tidymodels)

lm_spec <- # your model specification
  linear_reg() %>%  # model type
  set_engine(engine = "lm") %>%  # model engine
  set_mode("regression") # model mode

# Show your model specification
lm_spec

```


## Model training

In the training process, you run an algorithm on data and thereby produce a model. This process is also called model fitting.


```{r}

lm_fit <- # your fitted model
  fit( 
  lm_spec, # your model specification 
  Sale_Price ~ Gr_Liv_Area, # a Linear Regression formula 
  data = ames # your data
  )

```

Show your fitted model:

```{r}
tidy(lm_fit)
```

Show performance metrics for training data:

```{r}
glance(lm_fit$fit)
```



## Model predictions

We use our fitted model to make predictions. In this example, we again use our training data.

```{r}

price_pred <- 
  lm_fit %>% 
  predict(new_data = ames) %>%
  mutate(price_truth = ames$Sale_Price)

head(price_pred)

```



## Model evaluation 

We use the Root Mean Squared Error (RMSE) to evaluate our regression model. Therefore, we use the function $rmse(data, truth, estimate)$.

```{r}

rmse(data = price_pred, 
     truth = price_truth, 
     estimate = .pred)

```


Note: if we would want to make predictions for new houses, we could proceed as follows: 

```{r}

# New values (our x variable)
new_homes <- 
  tibble(Gr_Liv_Area = c(334, 1126, 1442, 1500, 1743, 5642)) 

# Prediction for new houses (predict y)
lm_fit %>%
 predict(new_data = new_homes)

```



# Process with data splitting

The best way to measure a model's performance at predicting new data is to actually predict new data.

This function "splits" data randomly into a single testing and a single training set: `initial_split(data, prop = 3/4, strata, breaks)`. We also use [stratified sampling](https://en.wikipedia.org/wiki/Stratified_sampling) in this example.

## Data splitting

```{r}

set.seed(100) 

ames_split <-  initial_split(ames,
                             strata = Sale_Price,
                             breaks = 4)

ames_train <-  training(ames_split)
ames_test <- testing(ames_split)

```

## Model type

```{r}

lm_spec_2 <-
  linear_reg() %>%  
  set_engine(engine = "lm") %>%  
  set_mode("regression") 

```

## Model training

```{r}
             
lm_fit_2 <- 
  lm_spec_2 %>% 
  fit(Sale_Price ~ Gr_Liv_Area,
      data = ames_train) # only use training data

```

## Model predictions

```{r}
 
price_pred_2 <- 
  lm_fit_2 %>% 
  predict(new_data = ames_test) %>% 
  mutate(price_truth = ames_test$Sale_Price)

```

## Model evaluation

```{r}

rmse(price_pred_2, 
     truth = price_truth, 
     estimate = .pred)

```

